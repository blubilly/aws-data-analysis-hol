{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Predict suvival on the Titanic with AWS Glue.\n",
    "### 타이타닉 사고에서 어떤 승객이 살아남을 수 있을 지 예측해보세요\n",
    "##### Kaggle은 2010년 설립된 예측모델 및 분석 대회 플랫폼입니다.\n",
    "##### 기업 및 단체에서 데이터와 해결과제를 등록하면, 데이터 과학자들이 이를 해결하는 모델을 개발하고 경쟁하는 곳입니다. \n",
    "##### 이번 Lab에서는 Kaggle에서 입문자용 tutorial로 사용되는 titanic competition을 Glue와 Spark ML을 사용해서 데이터 분석, ETL, ML을 사용한 Prediction까지 실습해보도록 하겠습니다.\n",
    "\n",
    "![titanic_sinking](images/titanic_sinking.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean, col, split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Glue 카탈로그에서 필요한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|passengerid|survived|pclass|                name|   sex| age|sibsp|parch|          ticket|   fare|cabin|embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|     Mr. Owen Harris|  male|22.0|    1|    0|       A/5 21171|   7.25|     |       S|\n",
      "|          2|       1|     1|Mrs. John Bradley...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|         Miss. Laina|female|26.0|    0|    0|STON/O2. 3101282|  7.925|     |       S|\n",
      "|          4|       1|     1|Mrs. Jacques Heat...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|   Mr. William Henry|  male|35.0|    0|    0|          373450|   8.05|     |       S|\n",
      "|          6|       0|     3|           Mr. James|  male|null|    0|    0|          330877| 8.4583|     |       Q|\n",
      "|          7|       0|     1|       Mr. Timothy J|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Master. Gosta Leo...|  male| 2.0|    3|    1|          349909| 21.075|     |       S|\n",
      "|          9|       1|     3|Mrs. Oscar W (Eli...|female|27.0|    0|    2|          347742|11.1333|     |       S|\n",
      "|         10|       1|     2|Mrs. Nicholas (Ad...|female|14.0|    1|    0|          237736|30.0708|     |       C|\n",
      "|         11|       1|     3|Miss. Marguerite Rut|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|     Miss. Elizabeth|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|   Mr. William Henry|  male|20.0|    0|    0|       A/5. 2151|   8.05|     |       S|\n",
      "|         14|       0|     3|    Mr. Anders Johan|  male|39.0|    1|    5|          347082| 31.275|     |       S|\n",
      "|         15|       0|     3|Miss. Hulda Amand...|female|14.0|    0|    0|          350406| 7.8542|     |       S|\n",
      "|         16|       1|     2|Mrs. (Mary D King...|female|55.0|    0|    0|          248706|   16.0|     |       S|\n",
      "|         17|       0|     3|      Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|     |       Q|\n",
      "|         18|       1|     2|  Mr. Charles Eugene|  male|null|    0|    0|          244373|   13.0|     |       S|\n",
      "|         19|       0|     3|Vander Mrs. Juliu...|female|31.0|    1|    0|          345763|   18.0|     |       S|\n",
      "|         20|       1|     3|         Mrs. Fatima|female|null|    0|    0|            2649|  7.225|     |       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from awsglue.context import GlueContext\n",
    " \n",
    "glueContext = GlueContext(sc)\n",
    "titanic_df = glueContext.create_dynamic_frame.from_catalog(database='analytics_hol',\n",
    "                                                           table_name='titanic_train',                           \n",
    "                                                           transformation_ctx='titanic_df').toDF()\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### passengerid: 승객 id\n",
    "##### survived: 생존여부 (0=No, 1=Yes)\n",
    "##### pclass: 티켓등급 (1=1st, 2=2nd, 3=3rd)\n",
    "##### name: 이름\n",
    "##### sex: 성별 (0=male, 1=female)\n",
    "##### age: 나이\n",
    "##### sibsp: 함께 탑승한 형제자매, 배우자의 수\n",
    "##### parch: 함께 탑승한 부모, 자식의 수\n",
    "##### ticket: 티켓번호\n",
    "##### fare: 운임\n",
    "##### cabin: 객실 번호\n",
    "##### embarked: 탑승항구 (C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. 전체 데이터 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891"
     ]
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. 데이터 스키마 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerid: long (nullable = true)\n",
      " |-- survived: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: long (nullable = true)\n",
      " |-- parch: long (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. 사용할 데이터에 모든 컬럼에 대해 요약 통계를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      passengerid|           survived|            pclass|                name|   sex|               age|             sibsp|              parch|            ticket|             fare|cabin|embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  891|     891|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|Andersen-Miss. Ca...|female|              0.42|                 0|                  0|            110152|              0.0|     |        |\n",
      "|    max|              891|                  1|                 3|    van Mr. Philemon|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+"
     ]
    }
   ],
   "source": [
    "titanic_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 전체 데이터가 891개로 다른 모든 컬럼은 891개의 데이터를 모두 가지고 있지만 age만 714개로 누락된 데이터가 존재함을 확인합니다.\n",
    "##### 빈 스트링은 이 요약 통계에서 구분이 불가능함으로 이후에 별도의 확인 과정을 통해 따로 체크하도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. 탑승객 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|survived|count|\n",
      "+--------+-----+\n",
      "|       0|  549|\n",
      "|       1|  342|\n",
      "+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('survived').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 891명의 승객 중 342명만 생존했음을 알 수 있습니다.\n",
    "##### 생존율은 sex, age, pclass와 같은 승객 특징들과 관련이 있으므로 해당 feature에 따른 생존율을 살펴봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. 성별에 따른 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|   sex|survived|count|\n",
      "+------+--------+-----+\n",
      "|female|       0|   81|\n",
      "|female|       1|  233|\n",
      "|  male|       0|  468|\n",
      "|  male|       1|  109|\n",
      "+------+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('sex', 'survived').count().orderBy('sex', 'survived', ascending=[1, 1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 남성보다 여성의 생존율이 높음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. 티켓등급에 따른 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|pclass|survived|count|\n",
      "+------+--------+-----+\n",
      "|     1|       0|   80|\n",
      "|     1|       1|  136|\n",
      "|     2|       0|   97|\n",
      "|     2|       1|   87|\n",
      "|     3|       0|  372|\n",
      "|     3|       1|  119|\n",
      "+------+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('pclass', 'survived').count().orderBy('pclass', 'survived', ascending=[1, 1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1등석의 생존율은 높고, 3등석의 생존율은 낮은 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. 함께 탑승한 형제자매나 배우자에 따른 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+\n",
      "|sibsp|survived|count|\n",
      "+-----+--------+-----+\n",
      "|    0|       0|  398|\n",
      "|    0|       1|  210|\n",
      "|    1|       0|   97|\n",
      "|    1|       1|  112|\n",
      "|    2|       0|   15|\n",
      "|    2|       1|   13|\n",
      "|    3|       0|   12|\n",
      "|    3|       1|    4|\n",
      "|    4|       0|   15|\n",
      "|    4|       1|    3|\n",
      "|    5|       0|    5|\n",
      "|    8|       0|    7|\n",
      "+-----+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('sibsp', 'survived').count().orderBy('sibsp', 'survived', ascending=[1, 1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 동승한 형제나매나 배우자가 없는 경우 생존율이 낮은 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. 함께 탑승한 부모님이나 자녀에 따른 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+\n",
      "|parch|survived|count|\n",
      "+-----+--------+-----+\n",
      "|    0|       0|  445|\n",
      "|    0|       1|  233|\n",
      "|    1|       0|   53|\n",
      "|    1|       1|   65|\n",
      "|    2|       0|   40|\n",
      "|    2|       1|   40|\n",
      "|    3|       0|    2|\n",
      "|    3|       1|    3|\n",
      "|    4|       0|    4|\n",
      "|    5|       0|    4|\n",
      "|    5|       1|    1|\n",
      "|    6|       0|    1|\n",
      "+-----+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('parch', 'survived').count().orderBy('parch', 'survived', ascending=[1, 1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 동승한 부모가 없는 경우 생존율이 낮은 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 탑승항구에 따른 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+\n",
      "|embarked|survived|count|\n",
      "+--------+--------+-----+\n",
      "|        |       1|    2|\n",
      "|       C|       0|   75|\n",
      "|       C|       1|   93|\n",
      "|       Q|       0|   47|\n",
      "|       Q|       1|   30|\n",
      "|       S|       0|  427|\n",
      "|       S|       1|  217|\n",
      "+--------+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('embarked', 'survived').count().orderBy('embarked', 'survived', ascending=[1, 1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2개의 데이터는 탑승항구가 명시되어 있지 않는 것을 알 수 있습니다.\n",
    "##### 탑승항구 S(Southampton)의 생존율이 낮은 것을 알 수 있습니다.\n",
    "##### 따라서, 탑승항구 S(Southampton)의 생존율이 낮은 이유를 알기 위해 탑승항구와 탑승석의 관계를 살펴볼 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|embarked|pclass|count|\n",
      "+--------+------+-----+\n",
      "|        |     1|    2|\n",
      "|       C|     1|   85|\n",
      "|       C|     2|   17|\n",
      "|       C|     3|   66|\n",
      "|       Q|     1|    2|\n",
      "|       Q|     2|    3|\n",
      "|       Q|     3|   72|\n",
      "|       S|     1|  127|\n",
      "|       S|     2|  164|\n",
      "|       S|     3|  353|\n",
      "+--------+------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('embarked', 'pclass').count().orderBy('embarked', 'pclass', ascending=[1, 1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 탑승항구 S(Southampton)의 생존율이 낮은 이유는 대다수 탑승객이 3등석이기 때문임을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Null Column Check\n",
    "##### Null 값이나 empty string을 가진 Column이 존재하는 지 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1. Null Value를 체크하기 위한 UDF 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_value_count(df):\n",
    "    null_columns_counts = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        nullRows = df.where((col(column).isNull()) | (col(column) == '')).count()\n",
    "    \n",
    "        if(nullRows > 0):\n",
    "              null_columns_counts.append((column, nullRows))\n",
    "    return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. null_value_count UDF를 이용하여 Null Value feature 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                   age|              177|\n",
      "|                 cabin|              687|\n",
      "|              embarked|                2|\n",
      "+----------------------+-----------------+"
     ]
    }
   ],
   "source": [
    "null_columns_count_list = null_value_count(titanic_df)\n",
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### age feature가 177개의 null value를 가진 것이 확인되었습니다.\n",
    "##### cabin feature가 687개의 empty string을 가진 것이 확인되었습니다.\n",
    "##### embarked feature가 2개의 empty string을 가진 것이 확인되었습니다.\n",
    "##### 이 정보는 이후 진행되는 feature engineering에서 참고 자료로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|     Mr. Owen Harris|\n",
      "|Mrs. John Bradley...|\n",
      "|         Miss. Laina|\n",
      "|Mrs. Jacques Heat...|\n",
      "|   Mr. William Henry|\n",
      "|           Mr. James|\n",
      "|       Mr. Timothy J|\n",
      "|Master. Gosta Leo...|\n",
      "|Mrs. Oscar W (Eli...|\n",
      "|Mrs. Nicholas (Ad...|\n",
      "|Miss. Marguerite Rut|\n",
      "|     Miss. Elizabeth|\n",
      "|   Mr. William Henry|\n",
      "|    Mr. Anders Johan|\n",
      "|Miss. Hulda Amand...|\n",
      "|Mrs. (Mary D King...|\n",
      "|      Master. Eugene|\n",
      "|  Mr. Charles Eugene|\n",
      "|Vander Mrs. Juliu...|\n",
      "|         Mrs. Fatima|\n",
      "+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 샘플 데이터에서 name field를 살펴보면 그대로 사용하기는 어렵고 정리가 필요하다는 것을 알 수 있습니다.\n",
    "##### name field에 나이와 성별 기혼 등을 의미하는 호칭(Mr, Mrs, Miss)이 있는 것을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1. name column에서 유의미한 호칭만 추출하여 별도의 initial column으로 만들고 기존 데이터에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n",
      "|passengerid|survived|pclass|                name|   sex| age|sibsp|parch|          ticket|   fare|cabin|embarked|initial|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n",
      "|          1|       0|     3|     Mr. Owen Harris|  male|22.0|    1|    0|       A/5 21171|   7.25|     |       S|     Mr|\n",
      "|          2|       1|     1|Mrs. John Bradley...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs|\n",
      "|          3|       1|     3|         Miss. Laina|female|26.0|    0|    0|STON/O2. 3101282|  7.925|     |       S|   Miss|\n",
      "|          4|       1|     1|Mrs. Jacques Heat...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs|\n",
      "|          5|       0|     3|   Mr. William Henry|  male|35.0|    0|    0|          373450|   8.05|     |       S|     Mr|\n",
      "|          6|       0|     3|           Mr. James|  male|null|    0|    0|          330877| 8.4583|     |       Q|     Mr|\n",
      "|          7|       0|     1|       Mr. Timothy J|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr|\n",
      "|          8|       0|     3|Master. Gosta Leo...|  male| 2.0|    3|    1|          349909| 21.075|     |       S| Master|\n",
      "|          9|       1|     3|Mrs. Oscar W (Eli...|female|27.0|    0|    2|          347742|11.1333|     |       S|    Mrs|\n",
      "|         10|       1|     2|Mrs. Nicholas (Ad...|female|14.0|    1|    0|          237736|30.0708|     |       C|    Mrs|\n",
      "|         11|       1|     3|Miss. Marguerite Rut|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss|\n",
      "|         12|       1|     1|     Miss. Elizabeth|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss|\n",
      "|         13|       0|     3|   Mr. William Henry|  male|20.0|    0|    0|       A/5. 2151|   8.05|     |       S|     Mr|\n",
      "|         14|       0|     3|    Mr. Anders Johan|  male|39.0|    1|    5|          347082| 31.275|     |       S|     Mr|\n",
      "|         15|       0|     3|Miss. Hulda Amand...|female|14.0|    0|    0|          350406| 7.8542|     |       S|   Miss|\n",
      "|         16|       1|     2|Mrs. (Mary D King...|female|55.0|    0|    0|          248706|   16.0|     |       S|    Mrs|\n",
      "|         17|       0|     3|      Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|     |       Q| Master|\n",
      "|         18|       1|     2|  Mr. Charles Eugene|  male|null|    0|    0|          244373|   13.0|     |       S|     Mr|\n",
      "|         19|       0|     3|Vander Mrs. Juliu...|female|31.0|    1|    0|          345763|   18.0|     |       S|    Mrs|\n",
      "|         20|       1|     3|         Mrs. Fatima|female|null|    0|    0|            2649|  7.225|     |       C|    Mrs|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn('initial', regexp_extract(col('name'), \"(\\w+)\\.\", 1))\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 생성된 initial feature의 데이터 분포 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| initial|count|\n",
      "+--------+-----+\n",
      "|      Mr|  517|\n",
      "|    Miss|  182|\n",
      "|     Mrs|  125|\n",
      "|  Master|   40|\n",
      "|      Dr|    7|\n",
      "|     Rev|    6|\n",
      "|   Major|    2|\n",
      "|     Col|    2|\n",
      "|    Mlle|    2|\n",
      "|Countess|    1|\n",
      "|     Mme|    1|\n",
      "|     Don|    1|\n",
      "|      Ms|    1|\n",
      "|    Capt|    1|\n",
      "|    Lady|    1|\n",
      "|Jonkheer|    1|\n",
      "|     Sir|    1|\n",
      "+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('initial').count().orderBy('count', ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mlle나 Mme 같이 Miss를 다르게 표현한 호칭도 확인할 수 있고, Master까지만 유의미하고 나머지는 하나로 그룹화하여 Other로 통합하는 것이 이후 데이터 분석에 효율적일 것으로 생각됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|initial|count|\n",
      "+-------+-----+\n",
      "|     Mr|  529|\n",
      "|   Miss|  186|\n",
      "|    Mrs|  127|\n",
      "| Master|   40|\n",
      "|  Other|    9|\n",
      "+-------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n",
    "titanic_df.groupBy(\"initial\").count().orderBy(\"count\", ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최종 정리된 Initial feature의 모습을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177"
     ]
    }
   ],
   "source": [
    "titanic_df.where((col('age').isNull()) | (col('age') == '')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### age에 177개의 빈 값은 적절하게 채워줘야 나중에 모델링할 때 성능을 높일 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1. age의 평균값을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         mean_age|\n",
      "+-----------------+\n",
      "|29.69911764705882|\n",
      "+-----------------+"
     ]
    }
   ],
   "source": [
    "# mean('age')의 output column 이름이 mean(age)여서 mean_age로 alias 함 \n",
    "titanic_df.select(mean('age').alias('mean_age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2. 전체 age의 평균은 29.70이나 우리는 initial feature를 알고 각 initial age 평균을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|initial|           avg_age|\n",
      "+-------+------------------+\n",
      "| Master| 4.574166666666667|\n",
      "|   Miss|             21.86|\n",
      "|     Mr| 32.73960880195599|\n",
      "|    Mrs|35.981818181818184|\n",
      "|  Other|45.888888888888886|\n",
      "+-------+------------------+"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "\n",
    "# avg('age')의 output column 이름이 avg(age)여서 avg_age로 alias 함 \n",
    "titanic_df.groupby('initial').agg(sf.avg('age').alias('avg_age')).orderBy('avg_age', ascending=[1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3. 각 initial age 평균을 알 수 있으므로 우리는 빈 age 값을 이를 이용하여 좀 더 스마트하게 채워줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn('age', when((titanic_df['initial'] == 'Miss') & (titanic_df['age'].isNull()), 22).otherwise(titanic_df['age']))\n",
    "titanic_df = titanic_df.withColumn('age', when((titanic_df['initial'] == 'Other') & (titanic_df['age'].isNull()), 46).otherwise(titanic_df['age']))\n",
    "titanic_df = titanic_df.withColumn('age', when((titanic_df['initial'] == 'Master') & (titanic_df['age'].isNull()), 5).otherwise(titanic_df['age']))\n",
    "titanic_df = titanic_df.withColumn('age', when((titanic_df['initial'] == 'Mr') & (titanic_df['age'].isNull()), 33).otherwise(titanic_df['age']))\n",
    "titanic_df = titanic_df.withColumn('age', when((titanic_df['initial'] == 'Mrs') & (titanic_df['age'].isNull()), 36).otherwise(titanic_df['age']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4. age의 요약 통계를 다시 확인합니다. null 값없이 891개의 값이 존재하며, 평균도 이전 값을 유지하고 있는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|               891|\n",
      "|   mean|29.841941638608304|\n",
      "| stddev|13.281524514031313|\n",
      "|    min|              0.42|\n",
      "|    max|              80.0|\n",
      "+-------+------------------+"
     ]
    }
   ],
   "source": [
    "titanic_df.select(col('age')).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "|        |    2|\n",
      "+--------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('embarked').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1. 대부분의 승객이 'S'에 해당하고 missing 값은 단 2개 뿐이므로 missing 값을 'S'로 채워줘도 큰 문제는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.na.fill({'embarked' : 'S'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687"
     ]
    }
   ],
   "source": [
    "titanic_df.where((col('cabin').isNull()) | (col('cabin') == '')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.1. cabin feacture는 대다수의 값이 빈 값으로 사용하기 어렵다고 판단되므로 drop 하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop('cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerid: long (nullable = true)\n",
      " |-- survived: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: long (nullable = true)\n",
      " |-- parch: long (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- embarked: string (nullable = false)\n",
      " |-- initial: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Schema에서 cabin feature가 drop 된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6. Family Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6.1. sibsp와 parch를 사용해서 family_size feature를 만들어 사용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn('family_Size', col('sibsp') + col('parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|family_size|count|\n",
      "+-----------+-----+\n",
      "|          0|  537|\n",
      "|          1|  161|\n",
      "|          2|  102|\n",
      "|          3|   29|\n",
      "|          5|   22|\n",
      "|          4|   15|\n",
      "|          6|   12|\n",
      "|         10|    7|\n",
      "|          7|    6|\n",
      "+-----------+-----+"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy('family_size').count().orderBy('count', ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6.2. family_size를 확인하니 대다수는 0이어서 alone feature를 따로 만들어 모델링에 사용하도록 하겠습니다.\n",
    "##### alone feature의 기본 값은 0으로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn('alone', lit(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### family_size가 0이면 alone feature를 1로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn('alone', when(titanic_df['family_size'] == 0, 1).otherwise(titanic_df['alone']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7. Create Index features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.7.1. 현재까지 생성된 column들을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['passengerid', 'survived', 'pclass', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'embarked', 'initial', 'family_Size', 'alone']"
     ]
    }
   ],
   "source": [
    "titanic_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.7.2. 이 중 sex, embarked, initial feature는 값이 string으로 되어있어 모델링에 사용할 수 없습니다. StringIndexer를 이용해서 number로 변환한 후 별도의 column으로 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "|passengerid|survived|pclass|                name|   sex| age|sibsp|parch|          ticket|   fare|embarked|initial|family_Size|alone|sex_index|embarked_index|initial_index|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "|          1|       0|     3|     Mr. Owen Harris|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|          1|    0|      0.0|           0.0|          0.0|\n",
      "|          2|       1|     1|Mrs. John Bradley...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|          1|    0|      1.0|           1.0|          2.0|\n",
      "|          3|       1|     3|         Miss. Laina|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n",
      "|          4|       1|     1|Mrs. Jacques Heat...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|          1|    0|      1.0|           0.0|          2.0|\n",
      "|          5|       0|     3|   Mr. William Henry|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|          6|       0|     3|           Mr. James|  male|33.0|    0|    0|          330877| 8.4583|       Q|     Mr|          0|    1|      0.0|           2.0|          0.0|\n",
      "|          7|       0|     1|       Mr. Timothy J|  male|54.0|    0|    0|           17463|51.8625|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|          8|       0|     3|Master. Gosta Leo...|  male| 2.0|    3|    1|          349909| 21.075|       S| Master|          4|    0|      0.0|           0.0|          3.0|\n",
      "|          9|       1|     3|Mrs. Oscar W (Eli...|female|27.0|    0|    2|          347742|11.1333|       S|    Mrs|          2|    0|      1.0|           0.0|          2.0|\n",
      "|         10|       1|     2|Mrs. Nicholas (Ad...|female|14.0|    1|    0|          237736|30.0708|       C|    Mrs|          1|    0|      1.0|           1.0|          2.0|\n",
      "|         11|       1|     3|Miss. Marguerite Rut|female| 4.0|    1|    1|         PP 9549|   16.7|       S|   Miss|          2|    0|      1.0|           0.0|          1.0|\n",
      "|         12|       1|     1|     Miss. Elizabeth|female|58.0|    0|    0|          113783|  26.55|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n",
      "|         13|       0|     3|   Mr. William Henry|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|         14|       0|     3|    Mr. Anders Johan|  male|39.0|    1|    5|          347082| 31.275|       S|     Mr|          6|    0|      0.0|           0.0|          0.0|\n",
      "|         15|       0|     3|Miss. Hulda Amand...|female|14.0|    0|    0|          350406| 7.8542|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n",
      "|         16|       1|     2|Mrs. (Mary D King...|female|55.0|    0|    0|          248706|   16.0|       S|    Mrs|          0|    1|      1.0|           0.0|          2.0|\n",
      "|         17|       0|     3|      Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q| Master|          5|    0|      0.0|           2.0|          3.0|\n",
      "|         18|       1|     2|  Mr. Charles Eugene|  male|33.0|    0|    0|          244373|   13.0|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|         19|       0|     3|Vander Mrs. Juliu...|female|31.0|    1|    0|          345763|   18.0|       S|    Mrs|          1|    0|      1.0|           0.0|          2.0|\n",
      "|         20|       1|     3|         Mrs. Fatima|female|36.0|    0|    0|            2649|  7.225|       C|    Mrs|          0|    1|      1.0|           1.0|          2.0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+'_index').fit(titanic_df) for column in ['sex', 'embarked', 'initial']]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "titanic_df = pipeline.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.7.3. 변경된 Schema를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerid: long (nullable = true)\n",
      " |-- survived: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: long (nullable = true)\n",
      " |-- parch: long (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- embarked: string (nullable = false)\n",
      " |-- initial: string (nullable = true)\n",
      " |-- family_Size: long (nullable = true)\n",
      " |-- alone: integer (nullable = false)\n",
      " |-- sex_index: double (nullable = true)\n",
      " |-- embarked_index: double (nullable = true)\n",
      " |-- initial_index: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8. Drop Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.8.1. 모델링에서 사용하지 않는 column들은 Drop 하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop('passengerid', 'name', 'ticket', 'cabin', 'embarked', 'sex', 'initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델링에 사용할 최종 데이터를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n",
      "|survived|pclass| age|sibsp|parch|   fare|family_Size|alone|sex_index|embarked_index|initial_index|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|          0.0|\n",
      "|       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|          2.0|\n",
      "|       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|\n",
      "|       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|          2.0|\n",
      "|       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|\n",
      "|       0|     3|33.0|    0|    0| 8.4583|          0|    1|      0.0|           2.0|          0.0|\n",
      "|       0|     1|54.0|    0|    0|51.8625|          0|    1|      0.0|           0.0|          0.0|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|          4|    0|      0.0|           0.0|          3.0|\n",
      "|       1|     3|27.0|    0|    2|11.1333|          2|    0|      1.0|           0.0|          2.0|\n",
      "|       1|     2|14.0|    1|    0|30.0708|          1|    0|      1.0|           1.0|          2.0|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|          2|    0|      1.0|           0.0|          1.0|\n",
      "|       1|     1|58.0|    0|    0|  26.55|          0|    1|      1.0|           0.0|          1.0|\n",
      "|       0|     3|20.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|\n",
      "|       0|     3|39.0|    1|    5| 31.275|          6|    0|      0.0|           0.0|          0.0|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|          0|    1|      1.0|           0.0|          1.0|\n",
      "|       1|     2|55.0|    0|    0|   16.0|          0|    1|      1.0|           0.0|          2.0|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|          5|    0|      0.0|           2.0|          3.0|\n",
      "|       1|     2|33.0|    0|    0|   13.0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|       0|     3|31.0|    1|    0|   18.0|          1|    0|      1.0|           0.0|          2.0|\n",
      "|       1|     3|36.0|    0|    0|  7.225|          0|    1|      1.0|           1.0|          2.0|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9. Put all features into vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.9.1. 모델에서 해당 feature들을 사용하기 위해서 VectorAssembler를 이용해서 vector화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=titanic_df.columns[1:], outputCol='features')\n",
    "feature_vector= feature.transform(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.9.2. features column이 추가된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "|survived|pclass| age|sibsp|parch|   fare|family_Size|alone|sex_index|embarked_index|initial_index|            features|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|          0.0|(10,[0,1,2,4,5],[...|\n",
      "|       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|          2.0|[1.0,38.0,1.0,0.0...|\n",
      "|       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|[3.0,26.0,0.0,0.0...|\n",
      "|       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|          2.0|[1.0,35.0,1.0,0.0...|\n",
      "|       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[3....|\n",
      "|       0|     3|33.0|    0|    0| 8.4583|          0|    1|      0.0|           2.0|          0.0|(10,[0,1,4,6,8],[...|\n",
      "|       0|     1|54.0|    0|    0|51.8625|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[1....|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|          4|    0|      0.0|           0.0|          3.0|[3.0,2.0,3.0,1.0,...|\n",
      "|       1|     3|27.0|    0|    2|11.1333|          2|    0|      1.0|           0.0|          2.0|[3.0,27.0,0.0,2.0...|\n",
      "|       1|     2|14.0|    1|    0|30.0708|          1|    0|      1.0|           1.0|          2.0|[2.0,14.0,1.0,0.0...|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|          2|    0|      1.0|           0.0|          1.0|[3.0,4.0,1.0,1.0,...|\n",
      "|       1|     1|58.0|    0|    0|  26.55|          0|    1|      1.0|           0.0|          1.0|[1.0,58.0,0.0,0.0...|\n",
      "|       0|     3|20.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[3....|\n",
      "|       0|     3|39.0|    1|    5| 31.275|          6|    0|      0.0|           0.0|          0.0|[3.0,39.0,1.0,5.0...|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|          0|    1|      1.0|           0.0|          1.0|[3.0,14.0,0.0,0.0...|\n",
      "|       1|     2|55.0|    0|    0|   16.0|          0|    1|      1.0|           0.0|          2.0|[2.0,55.0,0.0,0.0...|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|          5|    0|      0.0|           2.0|          3.0|[3.0,2.0,4.0,1.0,...|\n",
      "|       1|     2|33.0|    0|    0|   13.0|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[2....|\n",
      "|       0|     3|31.0|    1|    0|   18.0|          1|    0|      1.0|           0.0|          2.0|[3.0,31.0,1.0,0.0...|\n",
      "|       1|     3|36.0|    0|    0|  7.225|          0|    1|      1.0|           1.0|          2.0|[3.0,36.0,0.0,0.0...|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "feature_vector.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. 모델 평가를 위해 train 데이터와 test 데이터를 약 80:20 비율로 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2], seed=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       1.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       1.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol='survived', featuresCol='features')\n",
    "#Training algo\n",
    "lrModel = lr.fit(trainingData)\n",
    "lr_prediction = lrModel.transform(testData)\n",
    "lr_prediction.select('prediction', 'survived', 'features').show()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='survived', predictionCol='prediction', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating accuracy of LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is = 0.836257\n",
      "Test Error of LogisticRegression = 0.163743"
     ]
    }
   ],
   "source": [
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"Accuracy of LogisticRegression is = %g\" % (lr_accuracy))\n",
    "print(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       0.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       1.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol='survived', featuresCol='features')\n",
    "dt_model = dt.fit(trainingData)\n",
    "dt_prediction = dt_model.transform(testData)\n",
    "dt_prediction.select('prediction', 'survived', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating accuracy of DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier is = 0.807018\n",
      "Test Error of DecisionTreeClassifier = 0.192982"
     ]
    }
   ],
   "source": [
    "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
    "print(\"Accuracy of DecisionTreeClassifier is = %g\" % (dt_accuracy))\n",
    "print(\"Test Error of DecisionTreeClassifier = %g \" % (1.0 - dt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       0.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       1.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = DecisionTreeClassifier(labelCol='survived', featuresCol='features')\n",
    "rf_model = rf.fit(trainingData)\n",
    "rf_prediction = rf_model.transform(testData)\n",
    "rf_prediction.select('prediction', 'survived', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating accuracy of RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier is = 0.807018\n",
      "Test Error of RandomForestClassifier  = 0.192982"
     ]
    }
   ],
   "source": [
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"Accuracy of RandomForestClassifier is = %g\" % (rf_accuracy))\n",
    "print(\"Test Error of RandomForestClassifier  = %g \" % (1.0 - rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5. Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       1.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       1.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol='survived', featuresCol='features', maxIter=10)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "gbt_prediction = gbt_model.transform(testData)\n",
    "gbt_prediction.select('prediction', 'survived', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate accuracy of Gradient-boosted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gradient-boosted tree classifie is = 0.818713\n",
      "Test Error of Gradient-boosted tree classifie 0.181287"
     ]
    }
   ],
   "source": [
    "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Accuracy of Gradient-boosted tree classifie is = %g\" % (gbt_accuracy))\n",
    "print(\"Test Error of Gradient-boosted tree classifie %g\" % (1.0 - gbt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6. NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       1.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       1.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       1.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       1.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       1.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       1.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       1.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       1.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(labelCol='survived', featuresCol='features')\n",
    "nb_model = nb.fit(trainingData)\n",
    "nb_prediction = nb_model.transform(testData)\n",
    "nb_prediction.select('prediction', 'survived', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating accuracy of NaiveBayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes is  = 0.695906\n",
      "Test Error of NaiveBayes  = 0.304094"
     ]
    }
   ],
   "source": [
    "nb_accuracy = evaluator.evaluate(nb_prediction)\n",
    "print(\"Accuracy of NaiveBayes is  = %g\" % (nb_accuracy))\n",
    "print(\"Test Error of NaiveBayes  = %g \" % (1.0 - nb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       0.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "svm = LinearSVC(labelCol='survived', featuresCol='features')\n",
    "svm_model = svm.fit(trainingData)\n",
    "svm_prediction = svm_model.transform(testData)\n",
    "svm_prediction.select('prediction', 'survived', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the accuracy of Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine is = 0.836257\n",
      "Test Error of Support Vector Machine = 0.163743"
     ]
    }
   ],
   "source": [
    "svm_accuracy = evaluator.evaluate(svm_prediction)\n",
    "print(\"Accuracy of Support Vector Machine is = %g\" % (svm_accuracy))\n",
    "print(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8. Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위 테스트에서는 LogisticRegression과 Support Vector Machine이 83.6257%의 정확도로 가장 좋은 성능을 보여주었습니다.\n",
    "##### 하지만, 아직 기본적인 테스트만 수행하였으므로 개선할 여지가 많이 남아있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create your own model\n",
    "![kaggle_leaderboard](images/kaggle_leaderboard.png)\n",
    "#### 지금까지 다뤘던 기본적인 Feature engineering과 Modeling만으로 83.6%의 비교적 높은 정확도를 얻을 수 있었습니다. \n",
    "#### kaggle titanic competition에서 test 데이터에 대해서도 같은 정확도를 유지한다면 전체 10000명 중 상위 229등에 해당하는 높은 수치입니다. 하지만, 아직 개선할 여지가 많이 남아있습니다.\n",
    "#### * 첫 번째 접근할 수 있는 방법으로는 새로운 feacure를 추가하거나 기존 feature를 모델에서 제외하는 것입니다.\n",
    "#### * 두 번째 방법은 ML algorithm을 튜닝하는 것으로 아래 페이지를 참고하시면 됩니다.\n",
    "(https://spark.apache.org/docs/latest/ml-tuning.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  },
  "name": "01-kaggle-titanic-pyspark",
  "notebookId": 981946993289991
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
